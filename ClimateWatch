{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9042175,"sourceType":"datasetVersion","datasetId":5451342}],"dockerImageVersionId":30748,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/miguelangelastaiza/climatewatch?scriptVersionId=190652622\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import load_model\nfrom keras import regularizers, optimizers\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Conv2D,MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization, Input\nfrom sklearn.model_selection import train_test_split\nimport cv2 \nimport os\nimport time\nprint(\"Tensorflow version \" + tf.__version__)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-29T21:40:40.737937Z","iopub.execute_input":"2024-07-29T21:40:40.738277Z","iopub.status.idle":"2024-07-29T21:40:58.181032Z","shell.execute_reply.started":"2024-07-29T21:40:40.738247Z","shell.execute_reply":"2024-07-29T21:40:58.180196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\n    print('TPU initialized')\nexcept Exception as e:\n    print('Failed to initialize TPU:', e)\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:40:58.182405Z","iopub.execute_input":"2024-07-29T21:40:58.183101Z","iopub.status.idle":"2024-07-29T21:41:07.879382Z","shell.execute_reply.started":"2024-07-29T21:40:58.183068Z","shell.execute_reply":"2024-07-29T21:41:07.878089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_and_preprocess_images(folder_path):\n    image_data = []    #imagenes\n    labels = []        #etiquetas\n    i = 0\n    \n    for filename in os.listdir(folder_path):\n        if filename.endswith(\".jpg\"):\n            img = plt.imread(os.path.join(folder_path, filename))   #Leer imagen\n            img = cv2.resize(img, (800, 800))  # Redimensiona a un tamaño fijo\n            #img_flatten = img.flatten()  # Aplana la imagen a datos bidimensionales\n            #i += 1\n            #if i == 601:    #Para no leer todas las img\n                #break\n            \n            image_data.append(img)\n            if folder_path == \"/kaggle/input/climate-pop/Soleado\":\n                labels.append(0)\n            elif folder_path == \"/kaggle/input/climate-pop/Rain\":\n                labels.append(1)\n            else:\n                labels.append(2)\n            # 0 para imágenes de sol, 1 para imágenes de lluvia y 2 para imagenes de nublado\n    \n    return image_data, labels","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:41:07.880463Z","iopub.execute_input":"2024-07-29T21:41:07.880747Z","iopub.status.idle":"2024-07-29T21:41:07.886563Z","shell.execute_reply.started":"2024-07-29T21:41:07.880699Z","shell.execute_reply":"2024-07-29T21:41:07.885699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Carga de imagenes\nsol_data, sol_labels = load_and_preprocess_images(\"/kaggle/input/climate-pop/Soleado\")\nlluvia_data, lluvia_labels = load_and_preprocess_images(\"/kaggle/input/climate-pop/Rain\")\nnublado_data, nublado_labels = load_and_preprocess_images(\"/kaggle/input/climate-pop/Nublado\")\n\n# Combinar datos\ndata = np.array(sol_data + lluvia_data + nublado_data)\nlabels = np.array(sol_labels + lluvia_labels + nublado_labels)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:41:07.887485Z","iopub.execute_input":"2024-07-29T21:41:07.887707Z","iopub.status.idle":"2024-07-29T21:42:34.431384Z","shell.execute_reply.started":"2024-07-29T21:41:07.887685Z","shell.execute_reply":"2024-07-29T21:42:34.430106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_test_split recibe x,y y crea un paquete de 75% para entreno y 25% para prueba\nX_train, X_test, y_train, y_test = train_test_split(data,labels) # x son imagenes, y son etiquetas\n\nprint(X_train.shape) #imagenes de entreno\nprint(X_test.shape)  #imagenes de prueba","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:42:34.433859Z","iopub.execute_input":"2024-07-29T21:42:34.434148Z","iopub.status.idle":"2024-07-29T21:42:36.086477Z","shell.execute_reply.started":"2024-07-29T21:42:34.434122Z","shell.execute_reply":"2024-07-29T21:42:36.085292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(X_train[10]);\nprint(y_train[10])","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:42:36.08787Z","iopub.execute_input":"2024-07-29T21:42:36.088595Z","iopub.status.idle":"2024-07-29T21:42:36.403541Z","shell.execute_reply.started":"2024-07-29T21:42:36.088559Z","shell.execute_reply":"2024-07-29T21:42:36.40246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convertimos a flotante y normalizamos los datos solo de 0 a 1\ntrain_images = X_train.astype('float32') / 255     # dividimos entre 255 porque es el valor maximo de un pixel\ntest_images = X_test.astype('float32') / 255\n\n# para etiquetas \ntrain_labels = tf.keras.utils.to_categorical(y_train, 3)      # convertimos en un array de categoria, el 3 es porque existen 3 posibles clasificaciones\ntest_labels = tf.keras.utils.to_categorical(y_test, 3)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:42:36.40476Z","iopub.execute_input":"2024-07-29T21:42:36.405042Z","iopub.status.idle":"2024-07-29T21:42:48.7263Z","shell.execute_reply.started":"2024-07-29T21:42:36.405013Z","shell.execute_reply":"2024-07-29T21:42:48.725021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(train_images[10]);\nprint(train_labels[10])","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:42:48.727673Z","iopub.execute_input":"2024-07-29T21:42:48.728028Z","iopub.status.idle":"2024-07-29T21:42:49.020597Z","shell.execute_reply.started":"2024-07-29T21:42:48.727995Z","shell.execute_reply":"2024-07-29T21:42:49.019539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# division del dataset en 3: train, val y test\n\n(x_train, x_valid) = train_images[750:], train_images[:750]\n(y_train, y_valid) = train_labels[750:], train_labels[:750]\n\nprint('Imagenes de entreno:', x_train.shape[0])\nprint('Imagenes de validacion:', x_valid.shape[0])\nprint('Imagenes de test:', test_images.shape[0])","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:42:49.02193Z","iopub.execute_input":"2024-07-29T21:42:49.022212Z","iopub.status.idle":"2024-07-29T21:42:49.02829Z","shell.execute_reply.started":"2024-07-29T21:42:49.022186Z","shell.execute_reply":"2024-07-29T21:42:49.027187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope(): \n    model = keras.Sequential()\n    \n    # Definir la capa de entrada\n    model.add(Input(shape=(800, 800, 3)))   # input de 800 x 800 con 3 canales\n\n    # primera capa convolucional \n    model.add(Conv2D(filters=32, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(0.0001)))      \n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n\n    # Segunda capa convolucional\n    model.add(Conv2D(filters=32, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(0.0001)))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.2))\n\n    # Tercera capa convolucional\n    model.add(Conv2D(filters=64, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(0.0001)))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.3))\n\n    # Cuarta capa convolucional\n    model.add(Conv2D(filters=64, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(0.0001)))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.3))\n\n    # Capa de aplanamiento\n    model.add(Flatten())\n\n    # Capa densa de salida\n    model.add(Dense(3, activation='softmax'))      # solo 3 neuronas porque tenemos 3 posibles clasificaciones con softmax porque es para clasificar\n\n    model.summary()\n    \n    # Compilacion\n    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:42:49.029348Z","iopub.execute_input":"2024-07-29T21:42:49.029622Z","iopub.status.idle":"2024-07-29T21:42:50.366295Z","shell.execute_reply.started":"2024-07-29T21:42:49.029596Z","shell.execute_reply":"2024-07-29T21:42:50.365106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape[1:])","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:42:50.367604Z","iopub.execute_input":"2024-07-29T21:42:50.368301Z","iopub.status.idle":"2024-07-29T21:42:50.372497Z","shell.execute_reply.started":"2024-07-29T21:42:50.368264Z","shell.execute_reply":"2024-07-29T21:42:50.371686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape)\nprint(y_train.shape)\nprint(x_valid.shape)\nprint(y_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:42:50.373512Z","iopub.execute_input":"2024-07-29T21:42:50.373784Z","iopub.status.idle":"2024-07-29T21:42:50.385793Z","shell.execute_reply.started":"2024-07-29T21:42:50.37376Z","shell.execute_reply":"2024-07-29T21:42:50.385039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Entrenamiento\nwith strategy.scope(): \n    early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)\n    hist = model.fit(x_train, y_train, batch_size=16, epochs=12,          # batch_size indica que no voy a utilizar todas las imagenes por epoca si no pequeños lotes de 8\n                    validation_data=(x_valid, y_valid),\n                    callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:42:50.386753Z","iopub.execute_input":"2024-07-29T21:42:50.387042Z","iopub.status.idle":"2024-07-29T21:48:58.486928Z","shell.execute_reply.started":"2024-07-29T21:42:50.387015Z","shell.execute_reply":"2024-07-29T21:48:58.485509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizacion de la presicion\nplt.plot(hist.history['accuracy'],label='Train')\nplt.plot(hist.history['val_accuracy'],label='Val')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:49:33.721521Z","iopub.execute_input":"2024-07-29T21:49:33.721787Z","iopub.status.idle":"2024-07-29T21:49:33.846507Z","shell.execute_reply.started":"2024-07-29T21:49:33.72176Z","shell.execute_reply":"2024-07-29T21:49:33.845639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizacion de la perdida\nplt.plot(hist.history['loss'],label='Train')\nplt.plot(hist.history['val_loss'],label='Val')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:49:33.969187Z","iopub.execute_input":"2024-07-29T21:49:33.969503Z","iopub.status.idle":"2024-07-29T21:49:34.091799Z","shell.execute_reply.started":"2024-07-29T21:49:33.969471Z","shell.execute_reply":"2024-07-29T21:49:34.090892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope(): \n    model.evaluate(test_images,test_labels)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:48:58.770788Z","iopub.execute_input":"2024-07-29T21:48:58.771052Z","iopub.status.idle":"2024-07-29T21:49:33.587654Z","shell.execute_reply.started":"2024-07-29T21:48:58.771026Z","shell.execute_reply":"2024-07-29T21:49:33.586477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.saved_model.save(model, '/kaggle/working/climatewatch_model')\nprint(\"Modelo guardado exitosamente en /kaggle/working/\")","metadata":{"execution":{"iopub.status.busy":"2024-07-29T21:58:44.518993Z","iopub.execute_input":"2024-07-29T21:58:44.519401Z","iopub.status.idle":"2024-07-29T21:58:45.93153Z","shell.execute_reply.started":"2024-07-29T21:58:44.519359Z","shell.execute_reply":"2024-07-29T21:58:45.930701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\n# Define el nombre de la carpeta y el archivo ZIP\ncarpeta_a_comprimir = '/kaggle/working/climatewatch_model2'\narchivo_zip = '/kaggle/working/climatewatch_model2.zip'\n\n# Comprime la carpeta\nshutil.make_archive('/kaggle/working/climatewatch_model2', 'zip', carpeta_a_comprimir)\nprint(\"Carpeta comprimida exitosamente.\")","metadata":{"execution":{"iopub.status.busy":"2024-07-29T22:01:35.410591Z","iopub.execute_input":"2024-07-29T22:01:35.411312Z","iopub.status.idle":"2024-07-29T22:01:40.609008Z","shell.execute_reply.started":"2024-07-29T22:01:35.411274Z","shell.execute_reply":"2024-07-29T22:01:40.607982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Deteccion del estado del tiempo en tiempo real\n","metadata":{}},{"cell_type":"code","source":"# Cargar el modelo guardado\npath = \"/kaggle/working/climatewatch_model\"\n# Cargar el modelo usando TFSMLayer\nmodel = tf.keras.Sequential([\n    TFSMLayer(path, call_endpoint='serving_default')\n])\nprint(\"Modelo cargado exitosamente.\")\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inicializar la cámara\ncap = cv2.VideoCapture('http://192.168.0.3:8080/video')  \n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Preprocesar la imagen capturada\n    img1 = cv2.resize(frame, (800, 800))\n    img = img1 / 255  # Normalizar la imagen\n    img = np.expand_dims(img, axis=0)  # Agregar una dimensión para el batch\n    \n    # Hacer la predicción\n    pred_dict = model.predict(img)\n    pred = pred_dict[list(pred_dict.keys())[0]]\n    pred_class = np.argmax(pred, axis=-1)[0]  # Obtener la clase predicha\n\n    # Mostrar la predicción en la imagen\n    label = [\"Soleado\", \"Lluvia\", \"Nublado\"][pred_class]\n    cv2.putText(img1, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n    \n    # Mostrar la imagen\n    cv2.imshow('ClimateWatch', img1)\n    \n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n\ncap.release()\ncv2.destroyAllWindows()","metadata":{},"execution_count":null,"outputs":[]}]}